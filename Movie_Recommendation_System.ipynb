{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yr_8XuMH1ECx"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas scipy scikit-learn matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Create data directory\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Download MovieLens Small dataset\n",
        "print(\"Downloading MovieLens Small dataset...\")\n",
        "url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "urllib.request.urlretrieve(url, 'movielens.zip')\n",
        "\n",
        "# Extract\n",
        "with zipfile.ZipFile('movielens.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Copy to data folder\n",
        "import shutil\n",
        "shutil.copy('ml-latest-small/ratings.csv', 'data/ratings.csv')\n",
        "shutil.copy('ml-latest-small/movies.csv', 'data/movies.csv')\n",
        "\n",
        "print(\"✓ Dataset downloaded and extracted!\")\n",
        "print(f\"  Ratings file: {os.path.getsize('data/ratings.csv'):,} bytes\")\n",
        "print(f\"  Movies file: {os.path.getsize('data/movies.csv'):,} bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Ax8oiA1Giu",
        "outputId": "fa9554f7-365b-4a2a-94fb-76d9c9801563"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading MovieLens Small dataset...\n",
            "✓ Dataset downloaded and extracted!\n",
            "  Ratings file: 2,483,723 bytes\n",
            "  Movies file: 494,431 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ DATASET CONFIG ============\n",
        "DATA_DIR = \"data/\"\n",
        "RATINGS_FILE = \"ratings.csv\"\n",
        "MOVIES_FILE = \"movies.csv\"\n",
        "\n",
        "# Split ratios\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "# ============ PREPROCESSING CONFIG ============\n",
        "MIN_RATINGS_PER_USER = 5\n",
        "MIN_RATINGS_PER_MOVIE = 2\n",
        "\n",
        "# ============ BASELINE MODELS CONFIG ============\n",
        "PERCENTILE_FOR_POPULARITY = 75\n",
        "DAMPING_FACTOR = 50\n",
        "\n",
        "# ============ COLLABORATIVE FILTERING CONFIG ============\n",
        "NUM_NEIGHBORS = 10\n",
        "\n",
        "# ============ MATRIX FACTORIZATION CONFIG ============\n",
        "NUM_LATENT_FACTORS = 15\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# ============ HYBRID SYSTEM CONFIG ============\n",
        "DEFAULT_CF_WEIGHT = 0.5\n",
        "DEFAULT_CONTENT_WEIGHT = 0.25\n",
        "DEFAULT_POPULARITY_WEIGHT = 0.25\n",
        "\n",
        "# ============ EVALUATION CONFIG ============\n",
        "TOP_K_VALUES = [5, 10, 20]\n",
        "RATING_THRESHOLD = 3.5\n",
        "\n",
        "# ============ COLD-START CONFIG ============\n",
        "NEW_USER_RATINGS_THRESHOLD = 5\n",
        "NEW_MOVIE_RATINGS_THRESHOLD = 10\n",
        "\n",
        "# ============ INFERENCE CONFIG ============\n",
        "NUM_RECOMMENDATIONS = 10\n",
        "\n",
        "# ============ REPRODUCIBILITY ============\n",
        "SEED = 42\n",
        "\n",
        "print(\"✓ Configuration loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyDSeAr-1Glh",
        "outputId": "20cacfdc-2f8c-4ed8-9125-d9f95a1e5d16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Configuration loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Load and preprocess MovieLens dataset\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.ratings_df = None\n",
        "        self.movies_df = None\n",
        "        self.user_item_matrix = None\n",
        "        self.train_data = None\n",
        "        self.val_data = None\n",
        "        self.test_data = None\n",
        "        self.user_mapping = {}\n",
        "        self.movie_mapping = {}\n",
        "        self.reverse_user_mapping = {}\n",
        "        self.reverse_movie_mapping = {}\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load CSV files\"\"\"\n",
        "        ratings_path = f\"{DATA_DIR}{RATINGS_FILE}\"\n",
        "        movies_path = f\"{DATA_DIR}{MOVIES_FILE}\"\n",
        "\n",
        "        print(\"Loading ratings and movies data...\")\n",
        "        self.ratings_df = pd.read_csv(ratings_path)\n",
        "        self.movies_df = pd.read_csv(movies_path)\n",
        "\n",
        "        print(f\"  Ratings shape: {self.ratings_df.shape}\")\n",
        "        print(f\"  Movies shape: {self.movies_df.shape}\")\n",
        "\n",
        "        return self.ratings_df, self.movies_df\n",
        "\n",
        "    def analyze_sparsity(self) -> Dict:\n",
        "        \"\"\"Analyze data sparsity and basic statistics\"\"\"\n",
        "        if self.ratings_df is None:\n",
        "            self.load_data()\n",
        "\n",
        "        n_users = self.ratings_df['userId'].nunique()\n",
        "        n_movies = self.ratings_df['movieId'].nunique()\n",
        "        n_ratings = len(self.ratings_df)\n",
        "        sparsity = 1 - (n_ratings / (n_users * n_movies))\n",
        "\n",
        "        stats = {\n",
        "            'n_users': n_users,\n",
        "            'n_movies': n_movies,\n",
        "            'n_ratings': n_ratings,\n",
        "            'sparsity': sparsity,\n",
        "            'rating_mean': self.ratings_df['rating'].mean(),\n",
        "            'rating_std': self.ratings_df['rating'].std(),\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\" DATA SPARSITY ANALYSIS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Users: {stats['n_users']:,} | Movies: {stats['n_movies']:,} | Ratings: {stats['n_ratings']:,}\")\n",
        "        print(f\"Sparsity: {stats['sparsity']:.2%} (matrix is {stats['sparsity']:.2%} empty)\")\n",
        "        print(f\"Rating mean: {stats['rating_mean']:.2f} ± {stats['rating_std']:.2f}\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"Filter sparse data and create mappings\"\"\"\n",
        "        if self.ratings_df is None:\n",
        "            self.load_data()\n",
        "\n",
        "        print(f\"\\nFiltering users with < {MIN_RATINGS_PER_USER} ratings...\")\n",
        "        user_counts = self.ratings_df.groupby('userId').size()\n",
        "        valid_users = user_counts[user_counts >= MIN_RATINGS_PER_USER].index\n",
        "        self.ratings_df = self.ratings_df[self.ratings_df['userId'].isin(valid_users)]\n",
        "\n",
        "        print(f\"Filtering movies with < {MIN_RATINGS_PER_MOVIE} ratings...\")\n",
        "        movie_counts = self.ratings_df.groupby('movieId').size()\n",
        "        valid_movies = movie_counts[movie_counts >= MIN_RATINGS_PER_MOVIE].index\n",
        "        self.ratings_df = self.ratings_df[self.ratings_df['movieId'].isin(valid_movies)]\n",
        "\n",
        "        print(f\"After filtering: {self.ratings_df.shape[0]:,} ratings\")\n",
        "\n",
        "        # Create index mappings\n",
        "        unique_users = sorted(self.ratings_df['userId'].unique())\n",
        "        unique_movies = sorted(self.ratings_df['movieId'].unique())\n",
        "\n",
        "        self.user_mapping = {uid: idx for idx, uid in enumerate(unique_users)}\n",
        "        self.movie_mapping = {mid: idx for idx, mid in enumerate(unique_movies)}\n",
        "        self.reverse_user_mapping = {idx: uid for uid, idx in self.user_mapping.items()}\n",
        "        self.reverse_movie_mapping = {idx: mid for mid, idx in self.movie_mapping.items()}\n",
        "\n",
        "        # Add mapped columns\n",
        "        self.ratings_df['user_idx'] = self.ratings_df['userId'].map(self.user_mapping)\n",
        "        self.ratings_df['movie_idx'] = self.ratings_df['movieId'].map(self.movie_mapping)\n",
        "\n",
        "        return self.ratings_df\n",
        "\n",
        "    def build_user_item_matrix(self):\n",
        "        \"\"\"Build sparse user-item matrix\"\"\"\n",
        "        if self.ratings_df is None or 'user_idx' not in self.ratings_df.columns:\n",
        "            self.preprocess()\n",
        "\n",
        "        n_users = len(self.user_mapping)\n",
        "        n_movies = len(self.movie_mapping)\n",
        "\n",
        "        self.user_item_matrix = csr_matrix(\n",
        "            (self.ratings_df['rating'].values,\n",
        "             (self.ratings_df['user_idx'].values, self.ratings_df['movie_idx'].values)),\n",
        "            shape=(n_users, n_movies)\n",
        "        )\n",
        "\n",
        "        print(f\"User-item matrix shape: {self.user_item_matrix.shape}\")\n",
        "\n",
        "        return self.user_item_matrix\n",
        "\n",
        "    def train_val_test_split(self):\n",
        "        \"\"\"Split data into train, val, test\"\"\"\n",
        "        if self.ratings_df is None:\n",
        "            self.preprocess()\n",
        "\n",
        "        np.random.seed(SEED)\n",
        "\n",
        "        train_data_list = []\n",
        "        val_data_list = []\n",
        "        test_data_list = []\n",
        "\n",
        "        for user_id in self.ratings_df['user_idx'].unique():\n",
        "            user_ratings = self.ratings_df[self.ratings_df['user_idx'] == user_id].copy()\n",
        "            n = len(user_ratings)\n",
        "\n",
        "            if n < 3:\n",
        "                train_data_list.append(user_ratings)\n",
        "                continue\n",
        "\n",
        "            indices = np.random.permutation(n)\n",
        "            train_idx = int(np.ceil(n * TRAIN_RATIO))\n",
        "            val_idx = train_idx + int(np.ceil(n * VAL_RATIO))\n",
        "\n",
        "            train_data_list.append(user_ratings.iloc[indices[:train_idx]])\n",
        "            val_data_list.append(user_ratings.iloc[indices[train_idx:val_idx]])\n",
        "            test_data_list.append(user_ratings.iloc[indices[val_idx:]])\n",
        "\n",
        "        self.train_data = pd.concat(train_data_list, ignore_index=True) if train_data_list else pd.DataFrame()\n",
        "        self.val_data = pd.concat(val_data_list, ignore_index=True) if val_data_list else pd.DataFrame()\n",
        "        self.test_data = pd.concat(test_data_list, ignore_index=True) if test_data_list else pd.DataFrame()\n",
        "\n",
        "        print(f\"\\nTrain/Val/Test split:\")\n",
        "        print(f\"  Train: {len(self.train_data):,} ({len(self.train_data)/len(self.ratings_df):.1%})\")\n",
        "        print(f\"  Val:   {len(self.val_data):,} ({len(self.val_data)/len(self.ratings_df):.1%})\")\n",
        "        print(f\"  Test:  {len(self.test_data):,} ({len(self.test_data)/len(self.ratings_df):.1%})\")\n",
        "\n",
        "        return self.train_data, self.val_data, self.test_data\n",
        "\n",
        "    def get_movie_metadata(self) -> Dict:\n",
        "        \"\"\"Return movie metadata\"\"\"\n",
        "        if self.movies_df is None:\n",
        "            self.load_data()\n",
        "\n",
        "        metadata = {}\n",
        "        for _, row in self.movies_df.iterrows():\n",
        "            movie_id = row['movieId']\n",
        "            if movie_id in self.movie_mapping:\n",
        "                movie_idx = self.movie_mapping[movie_id]\n",
        "                metadata[movie_idx] = {\n",
        "                    'title': row['title'],\n",
        "                    'genres': row['genres'].split('|') if isinstance(row['genres'], str) else [],\n",
        "                }\n",
        "\n",
        "        return metadata\n",
        "\n",
        "print(\"✓ DataLoader class defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn38v-pH1Gn_",
        "outputId": "45f47e0d-479e-4872-b63f-1ceb48d8f71c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ DataLoader class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "class PopularityRecommender:\n",
        "    \"\"\"Recommend globally popular movies\"\"\"\n",
        "\n",
        "    def __init__(self, data_loader):\n",
        "        self.data_loader = data_loader\n",
        "        self.movie_scores = None\n",
        "\n",
        "    def fit(self, ratings_df: pd.DataFrame):\n",
        "        \"\"\"Learn movie popularity\"\"\"\n",
        "        movie_stats = ratings_df.groupby('movieId').agg({\n",
        "            'rating': ['mean', 'count']\n",
        "        }).reset_index()\n",
        "        movie_stats.columns = ['movieId', 'avg_rating', 'n_votes']\n",
        "\n",
        "        global_mean = ratings_df['rating'].mean()\n",
        "        min_votes = np.percentile(movie_stats['n_votes'], PERCENTILE_FOR_POPULARITY)\n",
        "\n",
        "        movie_stats['weighted_score'] = (\n",
        "            (movie_stats['n_votes'] * movie_stats['avg_rating'] +\n",
        "             min_votes * global_mean) /\n",
        "            (movie_stats['n_votes'] + min_votes)\n",
        "        )\n",
        "\n",
        "        self.movie_scores = dict(zip(movie_stats['movieId'], movie_stats['weighted_score']))\n",
        "\n",
        "    def recommend_for_user(self, user_id: int, k: int = NUM_RECOMMENDATIONS,\n",
        "                          exclude_watched: pd.DataFrame = None) -> list:\n",
        "        \"\"\"Return top-K popular movies\"\"\"\n",
        "        top_movies = sorted(self.movie_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        if exclude_watched is not None:\n",
        "            watched_movies = set(exclude_watched[exclude_watched['userId'] == user_id]['movieId'])\n",
        "        else:\n",
        "            watched_movies = set()\n",
        "\n",
        "        recommendations = []\n",
        "        for movie_id, score in top_movies:\n",
        "            if movie_id not in watched_movies:\n",
        "                recommendations.append(movie_id)\n",
        "                if len(recommendations) == k:\n",
        "                    break\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "class ContentBasedRecommender:\n",
        "    \"\"\"Recommend similar movies based on genres\"\"\"\n",
        "\n",
        "    def __init__(self, data_loader):\n",
        "        self.data_loader = data_loader\n",
        "        self.movie_metadata = None\n",
        "        self.genre_vectors = {}\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"Build genre-based vectors\"\"\"\n",
        "        self.movie_metadata = self.data_loader.get_movie_metadata()\n",
        "\n",
        "        all_genres = set()\n",
        "        for metadata in self.movie_metadata.values():\n",
        "            all_genres.update(metadata['genres'])\n",
        "        self.genre_list = sorted(list(all_genres))\n",
        "        self.genre_to_idx = {g: i for i, g in enumerate(self.genre_list)}\n",
        "\n",
        "        for movie_id, metadata in self.movie_metadata.items():\n",
        "            vector = np.zeros(len(self.genre_list))\n",
        "            for genre in metadata['genres']:\n",
        "                if genre in self.genre_to_idx:\n",
        "                    vector[self.genre_to_idx[genre]] = 1.0\n",
        "            if vector.sum() > 0:\n",
        "                vector = vector / vector.sum()\n",
        "            self.genre_vectors[movie_id] = vector\n",
        "\n",
        "    def get_similarity(self, movie_id1: int, movie_id2: int) -> float:\n",
        "        \"\"\"Cosine similarity between movies\"\"\"\n",
        "        if movie_id1 not in self.genre_vectors or movie_id2 not in self.genre_vectors:\n",
        "            return 0.0\n",
        "\n",
        "        vec1 = self.genre_vectors[movie_id1]\n",
        "        vec2 = self.genre_vectors[movie_id2]\n",
        "\n",
        "        if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        similarity = 1 - cosine(vec1, vec2)\n",
        "        return max(0, similarity)\n",
        "\n",
        "    def recommend_for_user(self, user_id: int, user_ratings_df: pd.DataFrame,\n",
        "                          k: int = NUM_RECOMMENDATIONS) -> list:\n",
        "        \"\"\"Find movies similar to user's favorites\"\"\"\n",
        "        user_watches = user_ratings_df[user_ratings_df['userId'] == user_id]\n",
        "        if len(user_watches) == 0:\n",
        "            return []\n",
        "\n",
        "        favorites = user_watches[user_watches['rating'] >= RATING_THRESHOLD]['movieId'].tolist()\n",
        "        if not favorites:\n",
        "            return []\n",
        "\n",
        "        similarity_scores = {}\n",
        "        watched_movies = set(user_watches['movieId'])\n",
        "\n",
        "        for candidate_movie in self.movie_metadata.keys():\n",
        "            if candidate_movie in watched_movies:\n",
        "                continue\n",
        "\n",
        "            similarities = [self.get_similarity(fav, candidate_movie) for fav in favorites]\n",
        "            avg_sim = np.mean(similarities)\n",
        "\n",
        "            if avg_sim > 0:\n",
        "                similarity_scores[candidate_movie] = avg_sim\n",
        "\n",
        "        top_similar = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "        return [movie_id for movie_id, sim in top_similar]\n",
        "\n",
        "print(\"✓ Baseline models defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fYXSBM71cQ3",
        "outputId": "8992f081-d8b2-4e29-feee-97a8fbe06803"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Baseline models defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "class MatrixFactorization:\n",
        "    \"\"\"SVD-based latent factor model\"\"\"\n",
        "\n",
        "    def __init__(self, n_latent_factors: int = NUM_LATENT_FACTORS):\n",
        "        self.n_latent_factors = n_latent_factors\n",
        "        self.U = None\n",
        "        self.sigma = None\n",
        "        self.Vt = None\n",
        "        self.global_mean = None\n",
        "\n",
        "    def fit(self, user_item_matrix):\n",
        "        \"\"\"Decompose matrix using SVD\"\"\"\n",
        "        print(f\"Fitting SVD with {self.n_latent_factors} latent factors...\")\n",
        "\n",
        "        self.global_mean = user_item_matrix.data.mean()\n",
        "        user_item_centered = user_item_matrix.copy()\n",
        "        user_item_centered.data -= self.global_mean\n",
        "\n",
        "        self.U, self.sigma, self.Vt = svds(\n",
        "            user_item_centered,\n",
        "            k=self.n_latent_factors,\n",
        "            random_state=RANDOM_STATE,\n",
        "            which='LM'\n",
        "        )\n",
        "\n",
        "        self.U = self.U[:, ::-1]\n",
        "        self.sigma = self.sigma[::-1]\n",
        "        self.Vt = self.Vt[::-1, :]\n",
        "\n",
        "        print(f\"  U shape: {self.U.shape}\")\n",
        "        print(f\"  Σ shape: {self.sigma.shape}\")\n",
        "        print(f\"  V^T shape: {self.Vt.shape}\")\n",
        "\n",
        "    def predict_rating(self, user_idx: int, movie_idx: int) -> float:\n",
        "        \"\"\"Predict rating\"\"\"\n",
        "        if self.U is None or user_idx >= self.U.shape[0] or movie_idx >= self.Vt.shape[1]:\n",
        "            return self.global_mean\n",
        "\n",
        "        user_factors = self.U[user_idx]\n",
        "        movie_factors = self.Vt[:, movie_idx]\n",
        "        predicted = self.global_mean + np.dot(user_factors, np.diag(self.sigma)) @ movie_factors\n",
        "        return float(np.clip(predicted, 0.5, 5.0))\n",
        "\n",
        "    def recommend_for_user(self, user_idx: int, k: int = NUM_RECOMMENDATIONS,\n",
        "                          watched_movies: set = None) -> list:\n",
        "        \"\"\"Predict ratings and return top-K\"\"\"\n",
        "        if self.U is None:\n",
        "            return []\n",
        "\n",
        "        user_factors = self.U[user_idx]\n",
        "        sigma_diag = np.diag(self.sigma)\n",
        "        predicted_ratings = self.global_mean + (user_factors @ sigma_diag @ self.Vt)\n",
        "\n",
        "        if watched_movies is None:\n",
        "            watched_movies = set()\n",
        "\n",
        "        candidates = []\n",
        "        for movie_idx, rating in enumerate(predicted_ratings):\n",
        "            if movie_idx not in watched_movies:\n",
        "                candidates.append((movie_idx, rating))\n",
        "\n",
        "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [movie_idx for movie_idx, rating in candidates[:k]]\n",
        "\n",
        "print(\"✓ Matrix Factorization defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSNO8g991cUW",
        "outputId": "06137ca4-d538-49bf-daa9-39db9e944eab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Matrix Factorization defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RankingEvaluator:\n",
        "    \"\"\"Ranking-based evaluation metrics\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def precision_at_k(predictions: list, ground_truth: list, k: int) -> float:\n",
        "        \"\"\"Precision@K\"\"\"\n",
        "        if len(predictions) == 0:\n",
        "            return 0.0\n",
        "        predictions_k = predictions[:k]\n",
        "        hits = len(set(predictions_k) & set(ground_truth))\n",
        "        return hits / k\n",
        "\n",
        "    @staticmethod\n",
        "    def recall_at_k(predictions: list, ground_truth: list, k: int) -> float:\n",
        "        \"\"\"Recall@K\"\"\"\n",
        "        if len(ground_truth) == 0:\n",
        "            return 0.0\n",
        "        predictions_k = predictions[:k]\n",
        "        hits = len(set(predictions_k) & set(ground_truth))\n",
        "        return hits / len(ground_truth)\n",
        "\n",
        "    @staticmethod\n",
        "    def ndcg_at_k(predictions: list, ground_truth_with_scores: dict, k: int) -> float:\n",
        "        \"\"\"NDCG@K\"\"\"\n",
        "        if len(ground_truth_with_scores) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        predictions_k = predictions[:k]\n",
        "        dcg = 0.0\n",
        "        for i, pred_id in enumerate(predictions_k):\n",
        "            if pred_id in ground_truth_with_scores:\n",
        "                relevance = ground_truth_with_scores[pred_id]\n",
        "                dcg += relevance / np.log2(i + 2)\n",
        "\n",
        "        ideal_relevances = sorted(ground_truth_with_scores.values(), reverse=True)[:k]\n",
        "        idcg = 0.0\n",
        "        for i, relevance in enumerate(ideal_relevances):\n",
        "            idcg += relevance / np.log2(i + 2)\n",
        "\n",
        "        if idcg == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return dcg / idcg\n",
        "\n",
        "print(\"✓ Evaluation metrics defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_prMWKL1cX3",
        "outputId": "486d2bee-b500-4965-82c7-1a6c5cd3e5b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Evaluation metrics defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridRecommender:\n",
        "    \"\"\"Weighted ensemble of multiple strategies\"\"\"\n",
        "\n",
        "    def __init__(self, data_loader, pop_rec, content_rec, mf_rec):\n",
        "        self.data_loader = data_loader\n",
        "        self.pop_rec = pop_rec\n",
        "        self.content_rec = content_rec\n",
        "        self.mf_rec = mf_rec\n",
        "\n",
        "        self.cf_weight = DEFAULT_CF_WEIGHT\n",
        "        self.content_weight = DEFAULT_CONTENT_WEIGHT\n",
        "        self.popularity_weight = DEFAULT_POPULARITY_WEIGHT\n",
        "\n",
        "    def set_weights(self, cf_weight: float, content_weight: float, popularity_weight: float):\n",
        "        \"\"\"Set hybrid weights\"\"\"\n",
        "        self.cf_weight = cf_weight\n",
        "        self.content_weight = content_weight\n",
        "        self.popularity_weight = popularity_weight\n",
        "\n",
        "    def recommend_for_user(self, user_id: int, user_idx: int, k: int = NUM_RECOMMENDATIONS,\n",
        "                          train_data = None) -> list:\n",
        "        \"\"\"Generate hybrid recommendations\"\"\"\n",
        "        watched_movies = set()\n",
        "        if train_data is not None:\n",
        "            watched_movies = set(train_data[train_data['userId'] == user_id]['movieId'])\n",
        "\n",
        "        # Get scores from each recommender\n",
        "        pop_recs = self.pop_rec.recommend_for_user(user_id, k=k*2, exclude_watched=train_data)\n",
        "        pop_scores = {movie_id: (k*2 - i) / (k*2) for i, movie_id in enumerate(pop_recs)}\n",
        "\n",
        "        content_recs = self.content_rec.recommend_for_user(user_id, self.data_loader.train_data, k=k*2)\n",
        "        content_scores = {movie_id: (k*2 - i) / (k*2) for i, movie_id in enumerate(content_recs)}\n",
        "\n",
        "        mf_watched_idx = {self.data_loader.movie_mapping.get(mid) for mid in watched_movies\n",
        "                          if mid in self.data_loader.movie_mapping}\n",
        "        mf_recs = self.mf_rec.recommend_for_user(user_idx, k=k*2, watched_movies=mf_watched_idx)\n",
        "        mf_scores = {self.data_loader.reverse_movie_mapping.get(idx): (k*2 - i) / (k*2)\n",
        "                     for i, idx in enumerate(mf_recs) if self.data_loader.reverse_movie_mapping.get(idx)}\n",
        "\n",
        "        # Combine scores\n",
        "        all_movies = set(pop_scores.keys()) | set(content_scores.keys()) | set(mf_scores.keys())\n",
        "        combined_scores = {}\n",
        "\n",
        "        for movie_id in all_movies:\n",
        "            combined_scores[movie_id] = (\n",
        "                self.cf_weight * mf_scores.get(movie_id, 0) +\n",
        "                self.content_weight * content_scores.get(movie_id, 0) +\n",
        "                self.popularity_weight * pop_scores.get(movie_id, 0)\n",
        "            )\n",
        "\n",
        "        top_movies = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "        return [movie_id for movie_id, score in top_movies]\n",
        "\n",
        "print(\"✓ Hybrid Recommender defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0G-dPf41sq4",
        "outputId": "0f76760f-344e-4b0c-b886-61f471d1d974"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Hybrid Recommender defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" HYBRID MOVIE RECOMMENDATION SYSTEM - GOOGLE COLAB EDITION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" 1. DATA LOADING & PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "data_loader = DataLoader()\n",
        "data_loader.load_data()\n",
        "stats = data_loader.analyze_sparsity()\n",
        "data_loader.preprocess()\n",
        "data_loader.build_user_item_matrix()\n",
        "data_loader.train_val_test_split()\n",
        "\n",
        "# 2. Train baseline models\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" 2. TRAINING BASELINE MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n[Popularity Recommender]\")\n",
        "pop_rec = PopularityRecommender(data_loader)\n",
        "pop_rec.fit(data_loader.train_data)\n",
        "top_popular = pop_rec.recommend_for_user(data_loader.train_data.iloc[0]['userId'], k=5)\n",
        "print(f\"  Sample recommendations: {top_popular}\\n\")\n",
        "\n",
        "print(\"[Content-Based Recommender]\")\n",
        "content_rec = ContentBasedRecommender(data_loader)\n",
        "content_rec.fit()\n",
        "print(f\"  Genres extracted: {len(content_rec.genre_list)}\\n\")\n",
        "\n",
        "# 3. Matrix Factorization\n",
        "print(\"=\"*70)\n",
        "print(\" 3. MATRIX FACTORIZATION (SVD)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "mf_rec = MatrixFactorization(n_latent_factors=NUM_LATENT_FACTORS)\n",
        "mf_rec.fit(data_loader.user_item_matrix)\n",
        "\n",
        "# 4. Hybrid System\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" 4. HYBRID RECOMMENDATION SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "hybrid_rec = HybridRecommender(data_loader, pop_rec, content_rec, mf_rec)\n",
        "print(f\"Initial weights: CF={hybrid_rec.cf_weight:.2f}, Content={hybrid_rec.content_weight:.2f}, Pop={hybrid_rec.popularity_weight:.2f}\\n\")\n",
        "\n",
        "# 5. Evaluation\n",
        "print(\"=\"*70)\n",
        "print(\" 5. RANKING-BASED EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "evaluator = RankingEvaluator()\n",
        "\n",
        "# Get test users\n",
        "test_users = data_loader.test_data['userId'].unique()[:10]\n",
        "all_precisions = []\n",
        "all_recalls = []\n",
        "all_ndcgs = []\n",
        "\n",
        "for user_id in test_users:\n",
        "    user_idx = data_loader.user_mapping.get(user_id)\n",
        "    if user_idx is None:\n",
        "        continue\n",
        "\n",
        "    # Get recommendations\n",
        "    recommendations = hybrid_rec.recommend_for_user(user_id, user_idx, k=10,\n",
        "                                                   train_data=data_loader.train_data)\n",
        "\n",
        "    # Get ground truth\n",
        "    user_test = data_loader.test_data[data_loader.test_data['userId'] == user_id]\n",
        "    ground_truth = user_test['movieId'].tolist()\n",
        "    ground_truth_scores = dict(zip(user_test['movieId'], user_test['rating']))\n",
        "\n",
        "    if not ground_truth:\n",
        "        continue\n",
        "\n",
        "    # Compute metrics\n",
        "    prec = evaluator.precision_at_k(recommendations, ground_truth, 10)\n",
        "    rec = evaluator.recall_at_k(recommendations, ground_truth, 10)\n",
        "    ndcg = evaluator.ndcg_at_k(recommendations, ground_truth_scores, 10)\n",
        "\n",
        "    all_precisions.append(prec)\n",
        "    all_recalls.append(rec)\n",
        "    all_ndcgs.append(ndcg)\n",
        "\n",
        "print(f\"\\nHybrid Recommender Performance (Test Set):\")\n",
        "print(f\"  Precision@10: {np.mean(all_precisions):.4f}\")\n",
        "print(f\"  Recall@10:    {np.mean(all_recalls):.4f}\")\n",
        "print(f\"  NDCG@10:      {np.mean(all_ndcgs):.4f}\")\n",
        "\n",
        "# 6. Sample Recommendations\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" 6. SAMPLE RECOMMENDATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "sample_users = data_loader.test_data['userId'].unique()[:3]\n",
        "\n",
        "for user_id in sample_users:\n",
        "    user_idx = data_loader.user_mapping.get(user_id)\n",
        "    if user_idx is None:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nUser {user_id}:\")\n",
        "    recommendations = hybrid_rec.recommend_for_user(user_id, user_idx, k=5,\n",
        "                                                   train_data=data_loader.train_data)\n",
        "\n",
        "    for i, movie_id in enumerate(recommendations, 1):\n",
        "        movie_title = data_loader.movies_df[data_loader.movies_df['movieId'] == movie_id]['title'].values\n",
        "        if len(movie_title) > 0:\n",
        "            print(f\"  {i}. {movie_title[0]}\")\n",
        "\n",
        "# 7. Summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" 7. SUMMARY & INSIGHTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(f\"  Users: {stats['n_users']:,}\")\n",
        "print(f\"  Movies: {stats['n_movies']:,}\")\n",
        "print(f\"  Ratings: {stats['n_ratings']:,}\")\n",
        "print(f\"  Sparsity: {stats['sparsity']:.2%}\")\n",
        "\n",
        "print(f\"\\nSystem Features:\")\n",
        "print(f\"  ✓ Multiple recommendation strategies\")\n",
        "print(f\"  ✓ Ranking-based evaluation (not RMSE)\")\n",
        "print(f\"  ✓ Hybrid ensemble approach\")\n",
        "print(f\"  ✓ Cold-start handling\")\n",
        "print(f\"  ✓ Matrix factorization (SVD)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" ✓ DEMO COMPLETE!\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c05rCRKL1suX",
        "outputId": "0c7b8099-327c-45ae-f69a-eece71491957"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " HYBRID MOVIE RECOMMENDATION SYSTEM - GOOGLE COLAB EDITION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " 1. DATA LOADING & PREPROCESSING\n",
            "======================================================================\n",
            "Loading ratings and movies data...\n",
            "  Ratings shape: (100836, 4)\n",
            "  Movies shape: (9742, 3)\n",
            "\n",
            "============================================================\n",
            " DATA SPARSITY ANALYSIS\n",
            "============================================================\n",
            "Users: 610 | Movies: 9,724 | Ratings: 100,836\n",
            "Sparsity: 98.30% (matrix is 98.30% empty)\n",
            "Rating mean: 3.50 ± 1.04\n",
            "\n",
            "Filtering users with < 5 ratings...\n",
            "Filtering movies with < 2 ratings...\n",
            "After filtering: 97,390 ratings\n",
            "User-item matrix shape: (610, 6278)\n",
            "\n",
            "Train/Val/Test split:\n",
            "  Train: 68,441 (70.3%)\n",
            "  Val:   14,900 (15.3%)\n",
            "  Test:  14,049 (14.4%)\n",
            "\n",
            "======================================================================\n",
            " 2. TRAINING BASELINE MODELS\n",
            "======================================================================\n",
            "\n",
            "[Popularity Recommender]\n",
            "  Sample recommendations: [318, 858, 50, 2571, 260]\n",
            "\n",
            "[Content-Based Recommender]\n",
            "  Genres extracted: 20\n",
            "\n",
            "======================================================================\n",
            " 3. MATRIX FACTORIZATION (SVD)\n",
            "======================================================================\n",
            "Fitting SVD with 15 latent factors...\n",
            "  U shape: (610, 15)\n",
            "  Σ shape: (15,)\n",
            "  V^T shape: (15, 6278)\n",
            "\n",
            "======================================================================\n",
            " 4. HYBRID RECOMMENDATION SYSTEM\n",
            "======================================================================\n",
            "Initial weights: CF=0.50, Content=0.25, Pop=0.25\n",
            "\n",
            "======================================================================\n",
            " 5. RANKING-BASED EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Hybrid Recommender Performance (Test Set):\n",
            "  Precision@10: 0.0700\n",
            "  Recall@10:    0.0509\n",
            "  NDCG@10:      0.0739\n",
            "\n",
            "======================================================================\n",
            " 6. SAMPLE RECOMMENDATIONS\n",
            "======================================================================\n",
            "\n",
            "User 1:\n",
            "  1. Shawshank Redemption, The (1994)\n",
            "  2. Forrest Gump (1994)\n",
            "  3. Godfather, The (1972)\n",
            "  4. Braveheart (1995)\n",
            "  5. Silence of the Lambs, The (1991)\n",
            "\n",
            "User 2:\n",
            "  1. Matrix, The (1999)\n",
            "  2. Fight Club (1999)\n",
            "  3. Lord of the Rings: The Return of the King, The (2003)\n",
            "  4. Dark Knight, The (2008)\n",
            "  5. Memento (2000)\n",
            "\n",
            "User 3:\n",
            "  1. Starship Troopers (1997)\n",
            "  2. Independence Day (a.k.a. ID4) (1996)\n",
            "  3. Ace Ventura: When Nature Calls (1995)\n",
            "  4. Mummy, The (1999)\n",
            "  5. Demolition Man (1993)\n",
            "\n",
            "======================================================================\n",
            " 7. SUMMARY & INSIGHTS\n",
            "======================================================================\n",
            "\n",
            "Dataset Statistics:\n",
            "  Users: 610\n",
            "  Movies: 9,724\n",
            "  Ratings: 100,836\n",
            "  Sparsity: 98.30%\n",
            "\n",
            "System Features:\n",
            "  ✓ Multiple recommendation strategies\n",
            "  ✓ Ranking-based evaluation (not RMSE)\n",
            "  ✓ Hybrid ensemble approach\n",
            "  ✓ Cold-start handling\n",
            "  ✓ Matrix factorization (SVD)\n",
            "\n",
            "======================================================================\n",
            " ✓ DEMO COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}